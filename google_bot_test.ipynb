{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05582ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_link = {'xp': ['https://www.google.com.br/alerts/feeds/09404460482838700245/5822277793724032524',\n",
    "                   'https://www.google.com.br/alerts/feeds/09404460482838700245/13683415329780998272',\n",
    "                   'https://www.google.com.br/alerts/feeds/09404460482838700245/10269129280916203083',\n",
    "                   'https://www.google.com.br/alerts/feeds/09404460482838700245/9550017878123396804'],\n",
    "            'vinci': ['https://www.google.com.br/alerts/feeds/09404460482838700245/5394093770400447553',\n",
    "                      'https://www.google.com.br/alerts/feeds/09404460482838700245/7598054495566054039',\n",
    "                      'https://www.google.com.br/alerts/feeds/09404460482838700245/13734905907790337986'],\n",
    "            'tivio': ['https://www.google.com.br/alerts/feeds/09404460482838700245/15089636150786167689',\n",
    "                      'https://www.google.com.br/alerts/feeds/09404460482838700245/14878059582149958709',\n",
    "                      'https://www.google.com.br/alerts/feeds/09404460482838700245/10293027038187432395'],\n",
    "            'tarpon': ['https://www.google.com.br/alerts/feeds/09404460482838700245/11130384113973110931',\n",
    "                       'https://www.google.com.br/alerts/feeds/09404460482838700245/13474059744439098265',\n",
    "                       'https://www.google.com.br/alerts/feeds/09404460482838700245/7060813333020958445'],\n",
    "            'bnp': ['https://www.google.com.br/alerts/feeds/09404460482838700245/15848728452539530082',\n",
    "                    'https://www.google.com.br/alerts/feeds/09404460482838700245/14146215433246553046',\n",
    "                    'https://www.google.com.br/alerts/feeds/09404460482838700245/14146215433246553144'],\n",
    "            'oceana': ['https://www.google.com.br/alerts/feeds/09404460482838700245/4978498206918616829',\n",
    "                       'https://www.google.com.br/alerts/feeds/09404460482838700245/15423088151033479411',\n",
    "                       'https://www.google.com.br/alerts/feeds/09404460482838700245/10556121544099713022'],\n",
    "        \n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807facae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur Braz\\monitoramento_midia\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas atuais da planilha: ['link_limpo', 'gestora', 'date', 'title', 'risco', 'tokens_utilizados', 'texto']\n",
      "[!] Conteúdo vazio: https://www.radiorock.com.br/noticias/10-melhores-podcasts-para-amantes-das-financas\n",
      "[!] Conteúdo vazio: https://www.youtube.com/watch?v=bTrAtUYHPnw\n",
      "[x] Erro ao baixar notícia: https://fusoesaquisicoes.com/acontece-no-setor/rbr-vende-toda-a-carteira-de-logistica-para-a-xp/\n",
      "Motivo: Article `download()` failed with 403 Client Error: Forbidden for url: https://fusoesaquisicoes.com/acontece-no-setor/rbr-vende-toda-a-carteira-de-logistica-para-a-xp/ on URL https://fusoesaquisicoes.com/acontece-no-setor/rbr-vende-toda-a-carteira-de-logistica-para-a-xp/\n",
      "\n",
      "[x] Erro ao baixar notícia: https://www.rockstargames.com/br/newswire/article/o327292o933k29/strange-tales-of-the-west-emerge-in-red-dead-online\n",
      "Motivo: Article `download()` failed with HTTPSConnectionPool(host='www.rockstargames.com', port=443): Max retries exceeded with url: /br/newswire/article/o327292o933k29/strange-tales-of-the-west-emerge-in-red-dead-online (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1028)'))) on URL https://www.rockstargames.com/br/newswire/article/o327292o933k29/strange-tales-of-the-west-emerge-in-red-dead-online\n",
      "\n",
      "[x] Erro ao baixar notícia: https://psxbrasil.com.br/novidades-em-red-dead-online-terriveis-contos-do-oeste/\n",
      "Motivo: Article `download()` failed with HTTPSConnectionPool(host='psxbrasil.com.br', port=443): Max retries exceeded with url: /novidades-em-red-dead-online-terriveis-contos-do-oeste/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1028)'))) on URL https://psxbrasil.com.br/novidades-em-red-dead-online-terriveis-contos-do-oeste/\n",
      "\n",
      "[x] Erro ao baixar notícia: https://br.ign.com/tech/142541/news/alguem-conectou-um-pc-com-windows-xp-desprotegido-a-internet-para-ver-o-que-aconteceria-e-resultado\n",
      "Motivo: Article `download()` failed with HTTPSConnectionPool(host='br.ign.com', port=443): Max retries exceeded with url: /tech/142541/news/alguem-conectou-um-pc-com-windows-xp-desprotegido-a-internet-para-ver-o-que-aconteceria-e-resultado (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1028)'))) on URL https://br.ign.com/tech/142541/news/alguem-conectou-um-pc-com-windows-xp-desprotegido-a-internet-para-ver-o-que-aconteceria-e-resultado\n",
      "\n",
      "[!] Conteúdo vazio: https://www.youtube.com/watch?v=bTrAtUYHPnw\n",
      "[x] Erro ao baixar notícia: https://br.investing.com/news/company-news/lenzing-inicia-periodo-de-estabilizacao-para-notas-perpetuas-93CH-1598172\n",
      "Motivo: Article `download()` failed with 403 Client Error: Forbidden for url: https://br.investing.com/news/company-news/lenzing-inicia-periodo-de-estabilizacao-para-notas-perpetuas-93CH-1598172 on URL https://br.investing.com/news/company-news/lenzing-inicia-periodo-de-estabilizacao-para-notas-perpetuas-93CH-1598172\n",
      "\n",
      "[x] Erro ao baixar notícia: https://br.investing.com/news/analyst-ratings/citi-eleva-precoalvo-das-acoes-da-fortive-para-us-59-apos-cisao-93CH-1597852\n",
      "Motivo: Article `download()` failed with 403 Client Error: Forbidden for url: https://br.investing.com/news/analyst-ratings/citi-eleva-precoalvo-das-acoes-da-fortive-para-us-59-apos-cisao-93CH-1597852 on URL https://br.investing.com/news/analyst-ratings/citi-eleva-precoalvo-das-acoes-da-fortive-para-us-59-apos-cisao-93CH-1597852\n",
      "\n",
      "[x] Erro ao baixar notícia: https://acionista.com.br/america-latina-brasil-se-destaca-entre-acoes-emergentes/\n",
      "Motivo: Article `download()` failed with 403 Client Error: Forbidden for url: https://acionista.com.br/america-latina-brasil-se-destaca-entre-acoes-emergentes/ on URL https://acionista.com.br/america-latina-brasil-se-destaca-entre-acoes-emergentes/\n",
      "\n",
      "Total estimado de tokens utilizados: 34237\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import feedparser\n",
    "from newspaper import Article, Config\n",
    "import google.generativeai as genai\n",
    "from json import dumps\n",
    "from httplib2 import Http\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "# ==================== CONFIGURAÇÕES ====================\n",
    "GOOGLE_SHEETS_CREDENTIALS = 'gen-lang-client-0013517676-0794cba51509.json'\n",
    "NOME_PLANILHA = 'historico-noticias'\n",
    "NOME_ABA = 'historico'\n",
    "\n",
    "\n",
    "def configurar_newspaper():\n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36'\n",
    "    config = Config()\n",
    "    config.browser_user_agent = user_agent\n",
    "    config.request_timeout = 10\n",
    "    return config\n",
    "\n",
    "\n",
    "def configurar_modelo():\n",
    "    genai.configure(api_key=\"AIzaSyAodyBl0O3ufE0x1-9nubUljeu6sOKQfjk\")\n",
    "    system_instruction = \"\"\"\n",
    "        Você é um especialista em compliance e riscos legais.\n",
    "        A empresa contrata serviços de diversas gestoras, que gerenciam nossos fundos de investimentos.\n",
    "        Sua tarefa é avaliar notícias e informar se uma gestora específica é alvo de algum processo/investigaçõa ou se é um risco legal ou à imagem da empresa.\n",
    "        As respostas devem ser **apenas uma das seguintes opções, exatamente como escrito**:\n",
    "        - 'risco' (Se está sob investigação/processo ou é um risco estar estar associado a imagem da gestora)\n",
    "        - 'possivel risco' (Se pode ser investigada/processada ou associado a imagem da gestora pode levantar duvidas)\n",
    "        - 'nao representa risco' (Não tem nenhum problema de imagem ou na justiça)\n",
    "        Não forneça explicações ou textos adicionais, apenas a palavra-chave.\n",
    "    \"\"\"\n",
    "    return genai.GenerativeModel(model_name=\"gemini-2.0-flash\", system_instruction=system_instruction)\n",
    "\n",
    "\n",
    "# ==================== GOOGLE PLANILHAS ====================\n",
    "def conectar_planilha():\n",
    "    scopes = [\n",
    "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "    \"https://www.googleapis.com/auth/drive\"]\n",
    "    creds = Credentials.from_service_account_file(GOOGLE_SHEETS_CREDENTIALS, scopes=scopes)\n",
    "    cliente = gspread.authorize(creds)\n",
    "    planilha = cliente.open(NOME_PLANILHA)\n",
    "    aba = planilha.worksheet(NOME_ABA)\n",
    "    return aba\n",
    "\n",
    "\n",
    "\n",
    "def carregar_historico_planilha(aba):\n",
    "    colunas_esperadas = ['link_limpo', 'gestora', 'date', 'title', 'risco', 'tokens_utilizados', 'texto']\n",
    "    try:\n",
    "        dados = aba.get_all_records()\n",
    "        if not dados:\n",
    "            print(\"[!] Planilha vazia. Inserindo cabeçalho padrão.\")\n",
    "            aba.insert_row(colunas_esperadas, index=1)\n",
    "            return pd.DataFrame(columns=colunas_esperadas)\n",
    "\n",
    "        df = pd.DataFrame(dados)\n",
    "        print(\"Colunas atuais da planilha:\", df.columns.tolist())  # DEBUG\n",
    "\n",
    "        for col in ['link_limpo']:\n",
    "            if col not in df.columns:\n",
    "                print(f\"[!] Coluna obrigatória '{col}' não encontrada. Reinicializando cabeçalho.\")\n",
    "                aba.clear()\n",
    "                aba.insert_row(colunas_esperadas, index=1)\n",
    "                return pd.DataFrame(columns=colunas_esperadas)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"[!] Erro ao carregar planilha. Detalhe:\", e)\n",
    "        return pd.DataFrame(columns=colunas_esperadas)\n",
    "\n",
    "\n",
    "def atualizar_planilha(aba, novos_df):\n",
    "    dados = novos_df[['link_limpo', 'gestora', 'date', 'title', 'risco', 'tokens_utilizados', 'texto']].values.tolist()\n",
    "    aba.append_rows(dados, value_input_option='USER_ENTERED')\n",
    "\n",
    "\n",
    "\n",
    "def filtrar_novas(news_df, historico_df):\n",
    "    if 'link_limpo' not in news_df.columns:\n",
    "        print(\"[!] DataFrame de notícias não tem 'link_limpo'. Retornando vazio.\")\n",
    "        return pd.DataFrame(columns=news_df.columns)\n",
    "    return news_df[~news_df['link_limpo'].isin(historico_df['link_limpo'])]\n",
    "\n",
    "# ==================== ALERTA GOOGLE CHAT ====================\n",
    "def sauron(gestora, titulo, link, risco):\n",
    "    url = \"https://chat.googleapis.com/v1/spaces/AAQAQI3Do4M/messages?key=AIzaSyDdI0hCZtE6vySjMm-WEfRq3CPzqKqqsHI&token=poG3A2pJAA9k1JOaVqICuCJyBuvpA_xaZReT-Ej40xE\"\n",
    "    app_message = {\n",
    "        \"text\": f'A {gestora} foi noticiada e representa um {risco} : \\n\\n{titulo}  \\n\\n{link}'\n",
    "    }\n",
    "    message_headers = {\"Content-Type\": \"application/json; charset=UTF-8\"}\n",
    "    http_obj = Http()\n",
    "    http_obj.request(\n",
    "        uri=url,\n",
    "        method=\"POST\",\n",
    "        headers=message_headers,\n",
    "        body=dumps(app_message),\n",
    "    )\n",
    "\n",
    "\n",
    "# ==================== EXTRAÇÃO DE NOTÍCIAS ====================\n",
    "def extrair_url_real(google_rss_url):\n",
    "    from urllib.parse import urlparse, parse_qs\n",
    "    \n",
    "    # Faz o parse da URL\n",
    "    parsed_url = urlparse(google_rss_url)\n",
    "    \n",
    "    # Extrai os parâmetros da query\n",
    "    params = parse_qs(parsed_url.query)\n",
    "    \n",
    "    # Pega o valor do parâmetro 'url'\n",
    "    url_real = params.get('url', [None])[0]\n",
    "    \n",
    "    return url_real\n",
    "\n",
    "def extrair_noticias(rss_link, config):\n",
    "    noticias = []\n",
    "\n",
    "    for gestora, urls in rss_link.items():\n",
    "        for url in urls:\n",
    "            feed = feedparser.parse(url)\n",
    "\n",
    "            for entry in feed.entries:\n",
    "                link_original = entry.link\n",
    "                link_limpo = extrair_url_real(link_original)\n",
    "\n",
    "                try:\n",
    "                    article = Article(link_limpo, config=config, language='pt')\n",
    "                    article.download()\n",
    "                    article.parse()\n",
    "\n",
    "                    if not article.text or article.text.strip() == \"\":\n",
    "                        print(f\"[!] Conteúdo vazio: {link_limpo}\")\n",
    "                        continue\n",
    "\n",
    "                    noticias.append({\n",
    "                        'gestora': gestora,\n",
    "                        'titulo': entry.title,\n",
    "                        'link': link_original,\n",
    "                        'link_limpo': link_limpo,\n",
    "                        'date': entry.published,\n",
    "                        'texto': article.text\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[x] Erro ao baixar notícia: {link_limpo}\\nMotivo: {e}\\n\")\n",
    "                    continue\n",
    "\n",
    "    return pd.DataFrame(noticias).drop_duplicates('link_limpo')\n",
    "\n",
    "\n",
    "# ==================== AVALIAÇÃO DE COMPLIANCE ====================\n",
    "def avaliar_risco(news_df, model):\n",
    "    resultados = []\n",
    "    total_tokens = 0\n",
    "\n",
    "    for ind in news_df.index:\n",
    "        url = news_df['link_limpo'][ind]\n",
    "        date = news_df['date'][ind]\n",
    "        gestora = news_df['gestora'][ind]\n",
    "        titulo = news_df['titulo'][ind]\n",
    "        texto = news_df['texto'][ind]\n",
    "\n",
    "        try:\n",
    "            prompt = f'A diretoria confiou a tarefa de ler e avaliar a seguinte notícia da {gestora}: {texto}'\n",
    "            response = model.generate_content(prompt,\n",
    "                                              generation_config={\"temperature\": 0.3})\n",
    "\n",
    "            tokens_prompt = len(prompt.split())\n",
    "            tokens_response = len(response.text.split())\n",
    "            total_tokens += tokens_prompt + tokens_response\n",
    "\n",
    "            risco = response.text.strip()\n",
    "            resultados.append({\n",
    "                'gestora': gestora,\n",
    "                'url': url,\n",
    "                'link_limpo': url,\n",
    "                'date': date,\n",
    "                'title': titulo,\n",
    "                'risco': risco,\n",
    "                'tokens_utilizados': tokens_prompt + tokens_response\n",
    "            })\n",
    "\n",
    "            if risco in ['risco', 'possivel risco']:\n",
    "                sauron(gestora, titulo, url, risco)\n",
    "\n",
    "            time.sleep(4)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[x] Erro no processamento de URL: {url}\\nMotivo: {e}\\n\")\n",
    "\n",
    "            if \"429\" in str(e):\n",
    "                print(\"[!] Limite excedido. Aguardando 60s...\\n\")\n",
    "                time.sleep(60)\n",
    "\n",
    "            resultados.append({\n",
    "                'gestora': gestora,\n",
    "                'url': url,\n",
    "                'link_limpo': url,\n",
    "                'date': date,\n",
    "                'title': titulo,\n",
    "                'risco': 'sem_info',\n",
    "                'tokens_utilizados': 0\n",
    "            })\n",
    "\n",
    "    print(f\"Total estimado de tokens utilizados: {total_tokens}\")\n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "\n",
    "# ==================== PONTO DE ENTRADA ====================\n",
    "def main():\n",
    "    config = configurar_newspaper()\n",
    "    model = configurar_modelo()\n",
    "    aba = conectar_planilha()\n",
    "\n",
    "    historico_df = carregar_historico_planilha(aba)\n",
    "    news_df = extrair_noticias(rss_link, config)\n",
    "    novas_noticias_df = filtrar_novas(news_df, historico_df)\n",
    "\n",
    "    if novas_noticias_df.empty:\n",
    "        print(\"Nenhuma nova notícia encontrada. Nada a processar.\")\n",
    "        return\n",
    "\n",
    "    novos_resultados_df = avaliar_risco(novas_noticias_df, model)\n",
    "\n",
    "    novos_resultados_df = novos_resultados_df.merge(\n",
    "        novas_noticias_df[['link_limpo', 'texto']], on='link_limpo', how='left'\n",
    "    )\n",
    "\n",
    "    atualizar_planilha(aba, novos_resultados_df)\n",
    "\n",
    "    #print(novos_resultados_df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
